{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sno': 1, 'homework': 19.37, 'discussion': 0, 'midterm': 35.0, 'grade': 'A'},\n",
       " {'sno': 2, 'homework': 20.0, 'discussion': 0, 'midterm': 34.12, 'grade': 'A'},\n",
       " {'sno': 3, 'homework': 19.37, 'discussion': 0, 'midterm': 34.3, 'grade': 'A'},\n",
       " {'sno': 4, 'homework': 18.12, 'discussion': 2, 'midterm': 31.5, 'grade': 'A'},\n",
       " {'sno': 5, 'homework': 20.0, 'discussion': 2, 'midterm': 33.25, 'grade': 'A'},\n",
       " {'sno': 6, 'homework': 19.37, 'discussion': 0, 'midterm': 24.5, 'grade': 'A'},\n",
       " {'sno': 7, 'homework': 19.37, 'discussion': 2, 'midterm': 23.8, 'grade': 'A'},\n",
       " {'sno': 8,\n",
       "  'homework': 16.87,\n",
       "  'discussion': 0,\n",
       "  'midterm': 28.87,\n",
       "  'grade': 'A'},\n",
       " {'sno': 9,\n",
       "  'homework': 19.37,\n",
       "  'discussion': 0,\n",
       "  'midterm': 29.75,\n",
       "  'grade': 'A'},\n",
       " {'sno': 10, 'homework': 20.0, 'discussion': 0, 'midterm': 31.5, 'grade': 'A'},\n",
       " {'sno': 11,\n",
       "  'homework': 19.37,\n",
       "  'discussion': 0,\n",
       "  'midterm': 29.57,\n",
       "  'grade': 'A'},\n",
       " {'sno': 12,\n",
       "  'homework': 19.37,\n",
       "  'discussion': 0,\n",
       "  'midterm': 31.5,\n",
       "  'grade': 'A'},\n",
       " {'sno': 13,\n",
       "  'homework': 19.37,\n",
       "  'discussion': 0,\n",
       "  'midterm': 29.75,\n",
       "  'grade': 'A'},\n",
       " {'sno': 14, 'homework': 20.0, 'discussion': 0, 'midterm': 31.5, 'grade': 'A'},\n",
       " {'sno': 15,\n",
       "  'homework': 18.12,\n",
       "  'discussion': 0,\n",
       "  'midterm': 28.0,\n",
       "  'grade': 'A'},\n",
       " {'sno': 16,\n",
       "  'homework': 19.37,\n",
       "  'discussion': 0,\n",
       "  'midterm': 24.5,\n",
       "  'grade': 'A'},\n",
       " {'sno': 17,\n",
       "  'homework': 20.0,\n",
       "  'discussion': 0,\n",
       "  'midterm': 30.62,\n",
       "  'grade': 'A'},\n",
       " {'sno': 18,\n",
       "  'homework': 19.37,\n",
       "  'discussion': 0,\n",
       "  'midterm': 30.62,\n",
       "  'grade': 'A'},\n",
       " {'sno': 19,\n",
       "  'homework': 19.37,\n",
       "  'discussion': 0,\n",
       "  'midterm': 24.5,\n",
       "  'grade': 'A'},\n",
       " {'sno': 20,\n",
       "  'homework': 19.37,\n",
       "  'discussion': 0,\n",
       "  'midterm': 28.0,\n",
       "  'grade': 'A'},\n",
       " {'sno': 21,\n",
       "  'homework': 19.37,\n",
       "  'discussion': 0,\n",
       "  'midterm': 35.0,\n",
       "  'grade': 'A'},\n",
       " {'sno': 22,\n",
       "  'homework': 16.87,\n",
       "  'discussion': 0,\n",
       "  'midterm': 35.0,\n",
       "  'grade': 'A'},\n",
       " {'sno': 23,\n",
       "  'homework': 19.37,\n",
       "  'discussion': 0,\n",
       "  'midterm': 29.75,\n",
       "  'grade': 'A'},\n",
       " {'sno': 24,\n",
       "  'homework': 19.37,\n",
       "  'discussion': 0,\n",
       "  'midterm': 28.0,\n",
       "  'grade': 'A'},\n",
       " {'sno': 25,\n",
       "  'homework': 19.37,\n",
       "  'discussion': 2,\n",
       "  'midterm': 35.0,\n",
       "  'grade': 'A'},\n",
       " {'sno': 26,\n",
       "  'homework': 16.87,\n",
       "  'discussion': 0,\n",
       "  'midterm': 30.45,\n",
       "  'grade': 'A'},\n",
       " {'sno': 27,\n",
       "  'homework': 19.37,\n",
       "  'discussion': 2,\n",
       "  'midterm': 22.75,\n",
       "  'grade': 'A'},\n",
       " {'sno': 28,\n",
       "  'homework': 19.37,\n",
       "  'discussion': 0,\n",
       "  'midterm': 35.0,\n",
       "  'grade': 'A'},\n",
       " {'sno': 29,\n",
       "  'homework': 16.25,\n",
       "  'discussion': 0,\n",
       "  'midterm': 26.25,\n",
       "  'grade': 'A'},\n",
       " {'sno': 30,\n",
       "  'homework': 16.87,\n",
       "  'discussion': 0,\n",
       "  'midterm': 28.0,\n",
       "  'grade': 'A'},\n",
       " {'sno': 31,\n",
       "  'homework': 15.0,\n",
       "  'discussion': 0,\n",
       "  'midterm': 28.87,\n",
       "  'grade': 'B'},\n",
       " {'sno': 32,\n",
       "  'homework': 20.0,\n",
       "  'discussion': 0,\n",
       "  'midterm': 30.62,\n",
       "  'grade': 'B'},\n",
       " {'sno': 33,\n",
       "  'homework': 19.37,\n",
       "  'discussion': 0,\n",
       "  'midterm': 23.45,\n",
       "  'grade': 'B'},\n",
       " {'sno': 34,\n",
       "  'homework': 20.0,\n",
       "  'discussion': 2,\n",
       "  'midterm': 26.25,\n",
       "  'grade': 'B'},\n",
       " {'sno': 35,\n",
       "  'homework': 18.12,\n",
       "  'discussion': 0,\n",
       "  'midterm': 28.0,\n",
       "  'grade': 'B'},\n",
       " {'sno': 36, 'homework': 20.0, 'discussion': 0, 'midterm': 28.0, 'grade': 'B'},\n",
       " {'sno': 37,\n",
       "  'homework': 16.87,\n",
       "  'discussion': 0,\n",
       "  'midterm': 24.5,\n",
       "  'grade': 'B'},\n",
       " {'sno': 38,\n",
       "  'homework': 20.0,\n",
       "  'discussion': 0,\n",
       "  'midterm': 25.37,\n",
       "  'grade': 'B'},\n",
       " {'sno': 39,\n",
       "  'homework': 13.75,\n",
       "  'discussion': 0,\n",
       "  'midterm': 33.25,\n",
       "  'grade': 'B'},\n",
       " {'sno': 40, 'homework': 20.0, 'discussion': 2, 'midterm': 24.5, 'grade': 'B'},\n",
       " {'sno': 41,\n",
       "  'homework': 19.37,\n",
       "  'discussion': 0,\n",
       "  'midterm': 24.5,\n",
       "  'grade': 'B'},\n",
       " {'sno': 42,\n",
       "  'homework': 19.37,\n",
       "  'discussion': 0,\n",
       "  'midterm': 22.75,\n",
       "  'grade': 'B'},\n",
       " {'sno': 43,\n",
       "  'homework': 19.37,\n",
       "  'discussion': 0,\n",
       "  'midterm': 22.57,\n",
       "  'grade': 'B'},\n",
       " {'sno': 44,\n",
       "  'homework': 17.5,\n",
       "  'discussion': 0,\n",
       "  'midterm': 29.75,\n",
       "  'grade': 'B'},\n",
       " {'sno': 45,\n",
       "  'homework': 19.37,\n",
       "  'discussion': 0,\n",
       "  'midterm': 30.62,\n",
       "  'grade': 'B'},\n",
       " {'sno': 46,\n",
       "  'homework': 19.37,\n",
       "  'discussion': 0,\n",
       "  'midterm': 24.5,\n",
       "  'grade': 'B'},\n",
       " {'sno': 47,\n",
       "  'homework': 20.0,\n",
       "  'discussion': 0,\n",
       "  'midterm': 29.75,\n",
       "  'grade': 'B'},\n",
       " {'sno': 48,\n",
       "  'homework': 16.87,\n",
       "  'discussion': 0,\n",
       "  'midterm': 19.25,\n",
       "  'grade': 'B'},\n",
       " {'sno': 49,\n",
       "  'homework': 16.87,\n",
       "  'discussion': 0,\n",
       "  'midterm': 27.82,\n",
       "  'grade': 'B'},\n",
       " {'sno': 50,\n",
       "  'homework': 19.37,\n",
       "  'discussion': 0,\n",
       "  'midterm': 25.37,\n",
       "  'grade': 'B'},\n",
       " {'sno': 51,\n",
       "  'homework': 18.75,\n",
       "  'discussion': 0,\n",
       "  'midterm': 33.25,\n",
       "  'grade': 'B'},\n",
       " {'sno': 52,\n",
       "  'homework': 17.5,\n",
       "  'discussion': 2,\n",
       "  'midterm': 22.75,\n",
       "  'grade': 'B'},\n",
       " {'sno': 53,\n",
       "  'homework': 15.62,\n",
       "  'discussion': 0,\n",
       "  'midterm': 21.0,\n",
       "  'grade': 'B'},\n",
       " {'sno': 54,\n",
       "  'homework': 19.37,\n",
       "  'discussion': 0,\n",
       "  'midterm': 24.5,\n",
       "  'grade': 'B'},\n",
       " {'sno': 55,\n",
       "  'homework': 17.5,\n",
       "  'discussion': 0,\n",
       "  'midterm': 18.37,\n",
       "  'grade': 'B'},\n",
       " {'sno': 56,\n",
       "  'homework': 20.0,\n",
       "  'discussion': 0,\n",
       "  'midterm': 19.25,\n",
       "  'grade': 'B'},\n",
       " {'sno': 57,\n",
       "  'homework': 16.87,\n",
       "  'discussion': 0,\n",
       "  'midterm': 26.25,\n",
       "  'grade': 'B'},\n",
       " {'sno': 58,\n",
       "  'homework': 20.0,\n",
       "  'discussion': 0,\n",
       "  'midterm': 28.87,\n",
       "  'grade': 'B'},\n",
       " {'sno': 59, 'homework': 17.5, 'discussion': 0, 'midterm': 23.8, 'grade': 'B'},\n",
       " {'sno': 60,\n",
       "  'homework': 19.37,\n",
       "  'discussion': 0,\n",
       "  'midterm': 26.25,\n",
       "  'grade': 'B'},\n",
       " {'sno': 61,\n",
       "  'homework': 19.37,\n",
       "  'discussion': 0,\n",
       "  'midterm': 21.0,\n",
       "  'grade': 'B'},\n",
       " {'sno': 62,\n",
       "  'homework': 19.37,\n",
       "  'discussion': 0,\n",
       "  'midterm': 21.0,\n",
       "  'grade': 'C'},\n",
       " {'sno': 63,\n",
       "  'homework': 19.37,\n",
       "  'discussion': 0,\n",
       "  'midterm': 21.17,\n",
       "  'grade': 'C'},\n",
       " {'sno': 64, 'homework': 20.0, 'discussion': 0, 'midterm': 24.5, 'grade': 'C'},\n",
       " {'sno': 65,\n",
       "  'homework': 16.87,\n",
       "  'discussion': 0,\n",
       "  'midterm': 21.7,\n",
       "  'grade': 'C'},\n",
       " {'sno': 66,\n",
       "  'homework': 19.37,\n",
       "  'discussion': 2,\n",
       "  'midterm': 21.87,\n",
       "  'grade': 'C'},\n",
       " {'sno': 67,\n",
       "  'homework': 19.37,\n",
       "  'discussion': 0,\n",
       "  'midterm': 15.75,\n",
       "  'grade': 'C'},\n",
       " {'sno': 68,\n",
       "  'homework': 19.37,\n",
       "  'discussion': 0,\n",
       "  'midterm': 17.5,\n",
       "  'grade': 'C'},\n",
       " {'sno': 69,\n",
       "  'homework': 19.37,\n",
       "  'discussion': 2,\n",
       "  'midterm': 14.87,\n",
       "  'grade': 'C'},\n",
       " {'sno': 70,\n",
       "  'homework': 16.87,\n",
       "  'discussion': 0,\n",
       "  'midterm': 21.0,\n",
       "  'grade': 'C'},\n",
       " {'sno': 71,\n",
       "  'homework': 16.87,\n",
       "  'discussion': 0,\n",
       "  'midterm': 15.75,\n",
       "  'grade': 'C'},\n",
       " {'sno': 72,\n",
       "  'homework': 19.37,\n",
       "  'discussion': 0,\n",
       "  'midterm': 19.25,\n",
       "  'grade': 'C'},\n",
       " {'sno': 73,\n",
       "  'homework': 19.37,\n",
       "  'discussion': 0,\n",
       "  'midterm': 24.5,\n",
       "  'grade': 'C'},\n",
       " {'sno': 74,\n",
       "  'homework': 19.37,\n",
       "  'discussion': 2,\n",
       "  'midterm': 22.75,\n",
       "  'grade': 'C'},\n",
       " {'sno': 75,\n",
       "  'homework': 16.25,\n",
       "  'discussion': 0,\n",
       "  'midterm': 24.5,\n",
       "  'grade': 'C'},\n",
       " {'sno': 76,\n",
       "  'homework': 19.37,\n",
       "  'discussion': 0,\n",
       "  'midterm': 12.25,\n",
       "  'grade': 'C'},\n",
       " {'sno': 77,\n",
       "  'homework': 15.62,\n",
       "  'discussion': 0,\n",
       "  'midterm': 16.62,\n",
       "  'grade': 'C'},\n",
       " {'sno': 78,\n",
       "  'homework': 15.0,\n",
       "  'discussion': 0,\n",
       "  'midterm': 15.05,\n",
       "  'grade': 'C'},\n",
       " {'sno': 79,\n",
       "  'homework': 16.87,\n",
       "  'discussion': 0,\n",
       "  'midterm': 11.9,\n",
       "  'grade': 'C'},\n",
       " {'sno': 80,\n",
       "  'homework': 16.87,\n",
       "  'discussion': 0,\n",
       "  'midterm': 22.05,\n",
       "  'grade': 'C'},\n",
       " {'sno': 81,\n",
       "  'homework': 18.12,\n",
       "  'discussion': 0,\n",
       "  'midterm': 10.5,\n",
       "  'grade': 'C'},\n",
       " {'sno': 82,\n",
       "  'homework': 20.0,\n",
       "  'discussion': 0,\n",
       "  'midterm': 12.95,\n",
       "  'grade': 'C'},\n",
       " {'sno': 83,\n",
       "  'homework': 19.37,\n",
       "  'discussion': 0,\n",
       "  'midterm': 13.12,\n",
       "  'grade': 'C'},\n",
       " {'sno': 84,\n",
       "  'homework': 18.75,\n",
       "  'discussion': 0,\n",
       "  'midterm': 17.5,\n",
       "  'grade': 'C'},\n",
       " {'sno': 85,\n",
       "  'homework': 19.37,\n",
       "  'discussion': 0,\n",
       "  'midterm': 14.0,\n",
       "  'grade': 'C'},\n",
       " {'sno': 86,\n",
       "  'homework': 18.75,\n",
       "  'discussion': 0,\n",
       "  'midterm': 6.12,\n",
       "  'grade': 'C'},\n",
       " {'sno': 87,\n",
       "  'homework': 19.37,\n",
       "  'discussion': 0,\n",
       "  'midterm': 11.37,\n",
       "  'grade': 'C'},\n",
       " {'sno': 88, 'homework': 20.0, 'discussion': 0, 'midterm': 9.62, 'grade': 'C'},\n",
       " {'sno': 89,\n",
       "  'homework': 19.37,\n",
       "  'discussion': 0,\n",
       "  'midterm': 6.12,\n",
       "  'grade': 'C'},\n",
       " {'sno': 90, 'homework': 18.75, 'discussion': 0, 'midterm': 3.5, 'grade': 'C'},\n",
       " {'sno': 91, 'homework': 0.0, 'discussion': 0, 'midterm': 3.5, 'grade': 'C'},\n",
       " {'sno': 92, 'homework': 5.0, 'discussion': 0, 'midterm': 0.0, 'grade': 'C'}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pymysql\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "conn = pymysql.connect(host = 'localhost' , user = 'root', password = 'Sheon@915' , db = 'university')\n",
    "curs = conn.cursor(pymysql.cursors.DictCursor)\n",
    "\n",
    "drop_sql = \"\"\"drop table if exists db_score_3_labels\"\"\"\n",
    "curs.execute(drop_sql)\n",
    "conn.commit()\n",
    "\n",
    "sql = \"\"\"\n",
    "    create table db_score_3_labels(\n",
    "        sno int primary key,\n",
    "        homework float,\n",
    "        discussion int,\n",
    "        midterm float,\n",
    "        grade char(1)\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "curs.execute(sql)\n",
    "conn.commit()\n",
    "\n",
    "xl_file = 'db_score_3_labels.xlsx'\n",
    "db_score_3_labels = pd.read_excel(xl_file)\n",
    "\n",
    "\n",
    "xl_file_rows = []\n",
    "for i in db_score_3_labels.values:\n",
    "    xl_file_rows.append(tuple(i))\n",
    "    \n",
    "sql2 = \"\"\"insert into db_score_3_labels(sno, homework, discussion, midterm, grade) values(%s, %s, %s, %s, %s)\"\"\"\n",
    "curs.executemany(sql2, xl_file_rows)\n",
    "conn.commit()\n",
    "\n",
    "sql3 = \"\"\"select * from db_score_3_labels\"\"\"\n",
    "curs.execute(sql3)\n",
    "data = curs.fetchall()\n",
    "display(data)\n",
    "\n",
    "curs.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_eval(y_test,y_predict):#첫번째 매개변수 : original data, 두번째 매개변수 : predicted data\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "    for y,yp in zip(y_test, y_predict):\n",
    "        if y == 1 and yp == 1:\n",
    "            tp += 1 #true positive\n",
    "        elif y == 1 and yp == -1:\n",
    "            fn += 1 #false negative\n",
    "        elif y == -1 and yp == -1:\n",
    "            tn += 1 #true negative\n",
    "        else:\n",
    "            fp += 1 #false positive\n",
    "            \n",
    "    accuracy = (tp+tn) / (tp+tn+fp+fn)\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    f1_score = 2*precision*recall/(precision+recall)\n",
    "    \n",
    "    return accuracy, precision, recall, f1_score\n",
    "            \n",
    "\n",
    "def performance_train_test_split(X,y):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn import tree\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42)\n",
    "    \n",
    "    print(y_train)\n",
    "    print(y_test)\n",
    "    \n",
    "    dtree = tree.DecisionTreeClassifier()\n",
    "    \n",
    "    dtree_model = dtree.fit(X_train, y_train)\n",
    "    \n",
    "    y_predict = dtree_model.predict(X_test)\n",
    "    \n",
    "    accuracy, precision, recall, f1_score = performance_eval(y_test, y_predict)\n",
    "    \n",
    "    print(\"<train_test_split performance evaluation>\")\n",
    "    print(\"accuracy=%f\" %accuracy)\n",
    "    print(\"precision=%f\" %precision)\n",
    "    print(\"recall=%f\" %recall)\n",
    "    print(\"f1_score=%f\" %f1_score)\n",
    "\n",
    "def performance_k_fold_cross_validation(X,y):\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn import tree\n",
    "    kf = KFold(n_splits = 10, random_state = 42, shuffle = True)\n",
    "    \n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1_score = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        dtree = tree.DecisionTreeClassifier()\n",
    "        dtree_model = dtree.fit(X_train, y_train)\n",
    "        y_predict = dtree_model.predict(X_test)\n",
    "        acc, prec, rec, f1 = performance_eval(y_test, y_predict)\n",
    "        accuracy.append(acc)\n",
    "        precision.append(prec)\n",
    "        recall.append(rec)\n",
    "        f1_score.append(f1)\n",
    "        \n",
    "    print(\"<k_fold_cross_validation performance evaluation>\")\n",
    "    print(\"accuracy array =\", accuracy)\n",
    "    print(\"precision array =\",precision)\n",
    "    print(\"recall array =\",recall)\n",
    "    print(\"f1_score array =\",f1_score)\n",
    "    \n",
    "    import statistics\n",
    "    print(\"average_accuracy =\", statistics.mean(accuracy))\n",
    "    print(\"average_precision =\", statistics.mean(precision))\n",
    "    print(\"average_recall =\", statistics.mean(recall))\n",
    "    print(\"average_f1_score =\", statistics.mean(f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1 -1  1  1 -1  1  1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1  1 -1 -1 -1 -1  1\n",
      " -1  1 -1  1  1  1 -1  1 -1 -1 -1 -1  1  1  1 -1  1  1 -1  1 -1 -1  1 -1\n",
      " -1  1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1  1]\n",
      "[ 1 -1  1 -1 -1 -1  1 -1 -1  1 -1  1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1  1\n",
      "  1 -1 -1 -1  1 -1 -1]\n",
      "<train_test_split performance evaluation>\n",
      "accuracy=0.967742\n",
      "precision=1.000000\n",
      "recall=0.888889\n",
      "f1_score=0.941176\n",
      "\n",
      "\n",
      "<k_fold_cross_validation performance evaluation>\n",
      "accuracy array = [1.0, 1.0, 0.8888888888888888, 1.0, 1.0, 1.0, 0.8888888888888888, 1.0, 1.0, 1.0]\n",
      "precision array = [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8333333333333334, 1.0, 1.0, 1.0]\n",
      "recall array = [1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "f1_score array = [1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.9090909090909091, 1.0, 1.0, 1.0]\n",
      "average_accuracy = 0.9777777777777777\n",
      "average_precision = 0.9833333333333334\n",
      "average_recall = 0.9666666666666667\n",
      "average_f1_score = 0.9709090909090909\n"
     ]
    }
   ],
   "source": [
    "X = [ (t['sno'], t['homework'], t['discussion'], t['midterm'])  for t in data ]\n",
    "X = np.array(X)\n",
    "\n",
    "y = [ 1 if (t['grade'] == 'B') else -1 for t in data ]\n",
    "y = np.array(y)\n",
    "\n",
    "performance_train_test_split(X,y)\n",
    "print('\\n')\n",
    "performance_k_fold_cross_validation(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_accuracy_eval(y1_test,y1_predict,y2_test, y2_predict, y3_test, y3_predict):\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "    for y,yp in zip(y1_test, y1_predict):\n",
    "        if y == 1 and yp == 1:\n",
    "            tp += 1 #true positive\n",
    "        elif y == -1 and yp == -1:\n",
    "            tn += 1 #true negative\n",
    "        elif y == 1 and yp == -1:\n",
    "            fp += 1 #false positive\n",
    "        else:\n",
    "            fn += 1 #false negative\n",
    "    for y,yp in zip(y2_test, y2_predict):\n",
    "        if y == 1 and yp == 1:\n",
    "            tp += 1 #true positive\n",
    "        elif y == -1 and yp == -1:\n",
    "            tn += 1 #true negative\n",
    "        elif y == 1 and yp == -1:\n",
    "            fp += 1 #false positive\n",
    "        else:\n",
    "            fn += 1 #false negative\n",
    "    for y,yp in zip(y3_test, y3_predict):\n",
    "        if y == 1 and yp == 1:\n",
    "            tp += 1 #true positive\n",
    "        elif y == -1 and yp == -1:\n",
    "            tn += 1 #true negative\n",
    "        elif y == 1 and yp == -1:\n",
    "            fp += 1 #false positive\n",
    "        else:\n",
    "            fn += 1 #false negative\n",
    "    accuracy = (tp+tn) / (tp+tn+fp+fn)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "def mc_others_eval(y_test,y_predict):#첫번째 매개변수 : original data, 두번째 매개변수 : predicted data\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "    for y,yp in zip(y_test, y_predict):\n",
    "        if y == 1 and yp == 1:\n",
    "            tp += 1 #true positive\n",
    "        elif y == 1 and yp == -1:\n",
    "            fn += 1 #false negative\n",
    "        elif y == -1 and yp == -1:\n",
    "            tn += 1 #true negative\n",
    "        else:\n",
    "            fp += 1 #false positive\n",
    "            \n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    f1_score = 2*precision*recall/(precision+recall)\n",
    "    \n",
    "    return precision, recall, f1_score\n",
    "\n",
    "def mc_performance_train_test_split(X,y1, y2, y3):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn import tree\n",
    "\n",
    "    X1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size = 0.33, random_state = 42)\n",
    "    X2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.33, random_state = 42)\n",
    "    X3_train, X3_test, y3_train, y3_test = train_test_split(X, y3, test_size = 0.33, random_state = 42)\n",
    "    \n",
    "    dtree = tree.DecisionTreeClassifier()\n",
    "    \n",
    "    dtree_model = dtree.fit(X1_train, y1_train)\n",
    "    dtree_model2 = dtree.fit(X2_train, y2_train)\n",
    "    dtree_model3 = dtree.fit(X3_train, y3_train)\n",
    "    \n",
    "    y1_predict = dtree_model.predict(X1_test)\n",
    "    y2_predict = dtree_model2.predict(X2_test)\n",
    "    y3_predict = dtree_model3.predict(X3_test)\n",
    "    \n",
    "    accuracy = mc_accuracy_eval(y1_test, y1_predict, y2_test, y2_predict, y3_test, y3_predict)\n",
    "  \n",
    "    print(\"<train_test_split performance evaluation>\")\n",
    "    print(\"accuracy=%f\" %accuracy)\n",
    "    \n",
    "    precision, recall, f1_score = mc_others_eval(y1_test, y1_predict)\n",
    "    \n",
    "    print(\"precision(A)=%f\" %precision)\n",
    "    print(\"recall(A)=%f\" %recall)\n",
    "    print(\"f1_score(A)=%f\" %f1_score)\n",
    "    \n",
    "    precision, recall, f1_score = mc_others_eval(y2_test, y2_predict)\n",
    "    \n",
    "    print(\"precision(B)=%f\" %precision)\n",
    "    print(\"recall(B)=%f\" %recall)\n",
    "    print(\"f1_score(B)=%f\" %f1_score)\n",
    "    \n",
    "    precision, recall, f1_score = mc_others_eval(y3_test, y3_predict)\n",
    "    \n",
    "    print(\"precision(C)=%f\" %precision)\n",
    "    print(\"recall(C)=%f\" %recall)\n",
    "    print(\"f1_score(C)=%f\" %f1_score)\n",
    "\n",
    "def mc_performance_k_fold_cross_validation(X,y1, y2, y3):\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn import tree\n",
    "    kf = KFold(n_splits = 4, random_state = 42, shuffle = True)\n",
    "    \n",
    "    accuracy = []\n",
    "    precision = [[],[],[]]\n",
    "    recall = [[],[],[]]\n",
    "    f1_score = [[],[],[]]\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y1_train, y1_test = y1[train_index], y1[test_index]\n",
    "        y2_train, y2_test = y2[train_index], y2[test_index]\n",
    "        y3_train, y3_test = y3[train_index], y3[test_index]\n",
    "        \n",
    "        dtree = tree.DecisionTreeClassifier()\n",
    "        dtree_model = dtree.fit(X_train, y1_train)\n",
    "        dtree_model2 = dtree.fit(X_train, y2_train)\n",
    "        dtree_model3 = dtree.fit(X_train, y3_train)\n",
    "    \n",
    "        y1_predict = dtree_model.predict(X_test)\n",
    "        y2_predict = dtree_model2.predict(X_test)\n",
    "        y3_predict = dtree_model3.predict(X_test)\n",
    "        \n",
    "        acc= mc_accuracy_eval(y1_test, y1_predict, y2_test, y2_predict, y3_test, y3_predict)\n",
    "        \n",
    "        accuracy.append(acc)\n",
    "        \n",
    "        prec, rec, f1  = mc_others_eval(y1_test, y1_predict)\n",
    "        precision[0].append(prec)\n",
    "        recall[0].append(rec)\n",
    "        f1_score[0].append(f1)\n",
    "        \n",
    "        prec, rec, f1  = mc_others_eval(y2_test, y2_predict)\n",
    "        precision[1].append(prec)\n",
    "        recall[1].append(rec)\n",
    "        f1_score[1].append(f1)\n",
    "        \n",
    "        prec, rec, f1  = mc_others_eval(y3_test, y3_predict)\n",
    "        precision[2].append(prec)\n",
    "        recall[2].append(rec)\n",
    "        f1_score[2].append(f1)\n",
    "        \n",
    "    print(\"<k_fold_cross_validation performance evaluation>\")\n",
    "    print(\"accuracy array =\", accuracy)\n",
    "    \n",
    "    print(\"precision(A) array =\",precision[0])\n",
    "    print(\"recall(A) array =\",recall[0])\n",
    "    print(\"f1_score(A) array =\",f1_score[0])\n",
    "    \n",
    "    print(\"precision(B) array =\",precision[1])\n",
    "    print(\"recall(B) array =\",recall[1])\n",
    "    print(\"f1_score(B) array =\",f1_score[1])\n",
    "    \n",
    "    print(\"precision(C) array =\",precision[2])\n",
    "    print(\"recall(C) array =\",recall[2])\n",
    "    print(\"f1_score(C) array =\",f1_score[2])\n",
    "    \n",
    "    import statistics\n",
    "    print(\"average_accuracy =\", statistics.mean(accuracy))\n",
    "    \n",
    "    print(\"average_precision(A) =\", statistics.mean(precision[0]))\n",
    "    print(\"average_recall(A) =\", statistics.mean(recall[0]))\n",
    "    print(\"average_f1_score(A) =\", statistics.mean(f1_score[0]))\n",
    "    \n",
    "    print(\"average_precision(B) =\", statistics.mean(precision[1]))\n",
    "    print(\"average_recall(B) =\", statistics.mean(recall[1]))\n",
    "    print(\"average_f1_score(B) =\", statistics.mean(f1_score[1]))\n",
    "    \n",
    "    print(\"average_precision(C) =\", statistics.mean(precision[2]))\n",
    "    print(\"average_recall(C) =\", statistics.mean(recall[2]))\n",
    "    print(\"average_f1_score(C) =\", statistics.mean(f1_score[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<train_test_split performance evaluation>\n",
      "accuracy=0.967742\n",
      "precision(A)=0.916667\n",
      "recall(A)=1.000000\n",
      "f1_score(A)=0.956522\n",
      "precision(B)=0.916667\n",
      "recall(B)=1.000000\n",
      "f1_score(B)=0.956522\n",
      "precision(C)=0.916667\n",
      "recall(C)=1.000000\n",
      "f1_score(C)=0.956522\n",
      "\n",
      "\n",
      "<k_fold_cross_validation performance evaluation>\n",
      "accuracy array = [1.0, 0.9565217391304348, 1.0, 1.0]\n",
      "precision(A) array = [1.0, 0.9, 1.0, 1.0]\n",
      "recall(A) array = [1.0, 1.0, 1.0, 1.0]\n",
      "f1_score(A) array = [1.0, 0.9473684210526316, 1.0, 1.0]\n",
      "precision(B) array = [1.0, 0.9, 1.0, 1.0]\n",
      "recall(B) array = [1.0, 1.0, 1.0, 1.0]\n",
      "f1_score(B) array = [1.0, 0.9473684210526316, 1.0, 1.0]\n",
      "precision(C) array = [1.0, 0.9, 1.0, 1.0]\n",
      "recall(C) array = [1.0, 1.0, 1.0, 1.0]\n",
      "f1_score(C) array = [1.0, 0.9473684210526316, 1.0, 1.0]\n",
      "average_accuracy = 0.9891304347826086\n",
      "average_precision(A) = 0.975\n",
      "average_recall(A) = 1.0\n",
      "average_f1_score(A) = 0.986842105263158\n",
      "average_precision(B) = 0.975\n",
      "average_recall(B) = 1.0\n",
      "average_f1_score(B) = 0.986842105263158\n",
      "average_precision(C) = 0.975\n",
      "average_recall(C) = 1.0\n",
      "average_f1_score(C) = 0.986842105263158\n"
     ]
    }
   ],
   "source": [
    "X = [ (t['sno'], t['homework'], t['discussion'], t['midterm'])  for t in data ]\n",
    "X = np.array(X)\n",
    "\n",
    "y1 = [ 1 if (t['grade'] == 'A') else -1 for t in data ]\n",
    "y1 = np.array(y1)\n",
    "\n",
    "y2 = [ 1 if (t['grade'] == 'B') else -1 for t in data ]\n",
    "y2 = np.array(y1)\n",
    "\n",
    "y3 = [ 1 if (t['grade'] == 'C') else -1 for t in data ]\n",
    "y3 = np.array(y1)\n",
    "\n",
    "\n",
    "mc_performance_train_test_split(X,y1, y2, y3)\n",
    "print('\\n')\n",
    "mc_performance_k_fold_cross_validation(X, y1, y2, y3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
